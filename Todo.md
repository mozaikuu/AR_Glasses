# Rules

-  ### **NEVER PUSH CODE TO "MAIN" OR "PROJECT DIVERGENCE"**
-  Only pick one task at a time
-  Do NOT fuck up the folder structure (it is fragile as it is)
-  Always comment next to code
-  Do not delete tasks that are done
-  Always add tasks followed by your name and a question mark in the **Suggestions** section
-  Always add tasks in order of urgency
-  If multiple people are assigned the same task then order people by amount of work done
-  When task is done add a checked box in the beginning
-  Add your name next to the task you assigned yourself and do not assign yourself multiple tasks for the future. (no dibs)
-  Do not mindlessly use AI
-  > Always try to do at least two tasks a week

### Urgent:

-  [ ] prepare documentation for first term [21/1/2026] (Duplicate)
~~-  [x] Prototype [4/1/2026]~~
-  [ ] docs
   -  [ ] requirements
   -  [ ] prototype
   -  [ ] expectations
   -  [ ] comparison
   -  [ ] files
      -  [ ] 4 pdf
      -  [ ] 1 word
      -  [ ] 1 img
      -  [ ] multiple diagrams
      -  [ ] sandy file
      -  [ ] sandy chat
      -  [x] Basma debriefing
-  [ ] Presentation
-  [ ] Code: DT_GB_148

### Abstract goals:

-  [ ] streamlit / flask
-  [ ] mobile test
-  [ ] fix nova
-  [ ] migrate to notion
-  [ ] hardware start
-  [ ] navigation start

### Current goal:

-  [ ] _Working Prototype on Mobile_

# Todo:

~~- [x] fix github~~

-  Make it work with a free api
-  fix text
-  fix audio and increase its accuracy

-  [ ] Restructure todo using nesting and Priority
-  [ ] Clean up Repo by removing unnecessary files

-  [ ] Features

   -  [ ] Indoor Navigation
   -  [ ] Speech to Text
   -  [x] Computer Vision
   -  [ ] Text to speech
   -  [x] search the web
   -  [ ] Take Notes (Tool)

-  [ ] Capture audio (Streamlit)
-  [ ] Capture Frame (Streamlit)
-  [x] Capture text (Streamlit)
-  [ ] Gyroscope Gps Orientation
-  [ ] Review old tasks
-  [ ] Buy Hardware
-  ~~[x] Streamlit~~
-  ~~[x] Mcp Server Test~~
-  ~~[x] Client test~~
-  [x] Gateway test
-  [ ] show response on phone
-  [ ] add more tools + ideas
-  [ ] AR Experience
-  [ ] When the model runs for too long the gateway disconnects and needs a restart from streamlit to reconnect
-  [ ] Review My code for more Fixes/ideas/documentation
-  [ ] audio and video are broken
-  [ ] Test Different Models
-  [ ] Choose the least busy path (Postponed)
-  [ ] img to real life mapping (Postponed)
-  [x] add thinking speeds
-  [ ] switch to Online LLMs
-  [ ] Eye Tracking (Postponed)
-  [ ] Docker/Onnx/Sdk/.EXE
-  [ ] Hololens EMULATOR (Postponed)
-  [ ] Our Hardware
-  [ ] Fully Agentic (Postponed)
-  [ ] Try Projector
-  [ ] Try Piece of Screen
-  [ ] Try Arduino?
-  [ ] Avatar AR (Postponed)
-  [ ] MQTT + Ngrok
-  [ ] Database
-  [ ] 3D-Mesh/Measure Building somehow (Postponed)
-  [ ] 2D Map of Building
-  [ ] Vuforia
-  [ ] Postman Problem
-  [ ] Response takes too much time... (HPC?)
-  [ ] audio/img do not refresh between prompts
-  [ ] camera is blue??
-  [ ] make everything automatic
-  [x] todo + rules
-  [ ] Hardware
   -  [ ] Glasses Design
   -  [ ] Parts
-  [ ] Notion
-  [ ] Ngrok / MQTT

---

-  Suggestions:
   -  add something idk

# TODO: Make this a checkbox section

---

# Competition

-  [ ] impact on society/industry specially telecommunication sector
-  [ ] clarity and validity of objectives
-  [ ] originality
-  [ ] writing and presentation quality
-  [ ] completing ALL the required fields
-  [ ] grammar and language
-  [ ] references are correct
-  [ ] PROJECT DESCRIPTION
   -  [ ] OVERVIEW
      -  [ ] (i) Problem definition
      -  [ ] (ii) approach and tools/techniques
      -  [ ] (iii) overview of system modules
      -  Use block diagrams and figures to describe your ideas. Be as clear as possible about the ideas in order to show the reviewer the value of your idea.
   -  [ ] IMPACT
      -  [ ] Why do you consider this project?
      -  [ ] What is its impact on community/market/end user/‚Ä¶ specially telecommunication sector?
   -  [ ] NOVELTY AND FEATURES
      -  [ ] Explain
         -  [ ] (i) novelty
         -  [ ] (ii) features
         -  [ ] (iii) related products
   -  [ ] DELIVERABLES
      -  [ ] What is the project final outcome (HW device, SW package, simulation ...)?
      -  It is important to clearly identify the final outcomes supported by evidence and results.
   -  [ ] BUSINESS PLAN AND MARKET ANALYSIS
      -  [ ] Market research
         -  [ ] product national or multinational
         -  [ ] business opportunities
         -  [ ] niche added value.
         -  [ ] potential market for your project?
         -  [ ] Do you expect any demand on the final product?
   -  [ ] Project EXPENSES
      -  [ ] List:
         -  [ ] equipment
         -  [ ] tools
         -  [ ] modules
         -  [ ] components
         -  [ ] software
         -  [ ] ‚Ä¶
         -  [ ] Item
         -  [ ] Type
         -  [ ] (Hardware/ Software/ Other)
         -  [ ] Specifications, (brief description)
         -  [ ] Cost (LE.)
         -  [ ] Total Project Cost

---

# Final

‚Ä¢ Project Requirements
ÔÉ∞ Project Contents
Students should work on preparing power point slides include the following:

-  Problem Overview
-  Introduction and Motivations
-  Project Goals
-  Previous/Related Projects
-  Requirements Analysis
-  System Design Models:
   o For Software Projects: May include some or all of the following:
   ‚ñ™ Class Responsibility Collaborator (CRC) Cards
   ‚ñ™ Flowchart Diagrams
   ‚ñ™ UML diagrams (Uses Cases/Class Diagram/ Component Diagram ‚Ä¶etc.)
   ‚ñ™ System Components and Architectural Diagrams
   ‚ñ™ DFD Diagrams
   ‚ñ™ Database Diagrams (Schema, ER-Diagram)
   ‚ñ™ Deployment Diagram
   ‚ñ™ Package Diagram
   ‚ñ™ UI sketches
   o For Hardware Projects: May include some or all of the following:
   ‚ñ™ Block Diagram
   ‚ñ™ Circuit Diagrams/Schematic diagrams
   ‚ñ™ Pin diagram
   ‚ñ™ Timing diagram
   ‚ñ™ Flowchart
   ‚ñ™ State Diagram
   ‚ñ™ PCB Layout Diagram
   ‚ñ™ System Architecture Diagram
   ‚ñ™ Data Flow Diagram
   ‚ñ™ Power Distribution Diagram
-  Used Technologies and tools
-  Time Plan (Project -1 only)
-  Business Plan
-  Roles of Team Members
-  Prototype Implementation (Mandatory for Project -2, Optional for Project-1)
-  Results/Testing and Outcomes
-  Conclusions and future Works
-  References
   ‚Ä¢ Presentation
   ÔÉ∞ Innovative slides that summarize the project contents in 20 minutes and it is built with the following
   features:
   o Contents Features:
   ‚ñ™ Focused: focus on what you did and why it matters
   ‚ñ™ Clear Contribution: what you built or proved
   ‚ñ™ Emphasize results: what you achieved and how it was validated
   o Appearance Features
   ‚ñ™ Consistent Theme: Use a clean, professional template
   ‚ñ™ Readable Fonts: Use large font (min 24pt), clear contrast
   ‚ñ™ Minimal Text: Avoid paragraphs‚Äîuse bullets
   ‚ñ™ Visuals: Add diagrams, charts, images where possible
   ‚ñ™ Code/Math: Use readable formatting or screenshots
   ÔÉ∞ Delivery of the presentation should be managed well by the team members and follow the following
   tips:
   ‚ñ™ Divide the presentation into logical sections (e.g., Intro, Design, Implementation,
   Results).
   ‚ñ™ Ensure equal participation so everyone speaks.
   ‚ñ™ Assign each section based on team members‚Äô strengths and contributions.
   ‚ñ™ Practice how you‚Äôll hand over to each other. For example:
   ‚ÄúNow my teammate [Name] will explain the system architecture.‚Äù
   ‚ñ™ Avoid awkward pauses or interruptions.
   ‚ñ™ Know each other‚Äôs parts well enough to back each other up if needed.
   ‚ñ™ Use the same terminology, tone, and pace.
   ‚ñ™ Make sure everyone follows the same slide format and presentation style (don‚Äôt mix
   formal and casual tones).
   ‚ñ™ Respect time limits (15‚Äì20 minutes is common)
   ‚ñ™ Have someone track time and make adjustments if needed.
   ‚ñ™ Practice together timing
   ‚ñ™ Speak clearly and confidently
   ‚ñ™ Don't read slides‚Äîexplain them
   ‚ñ™ Prepare for possible questions
   ‚ñ™ Agree in advance who will answer which types of questions.
   ‚ñ™ If a question is more relevant to another member, pass it politely:
   ‚ñ™ Pay attention to teammates when they‚Äôre speaking‚Äîdon‚Äôt look disengaged
   ‚ñ™ Don‚Äôt talk among yourselves or check your phone.
   ‚Ä¢ Documentation
-  Use the approved NMU-CSE Graduation Project Template
-  Final documentation must be submitted 2days before the date of the final Discussion
   (To be announced later)
-  Document Format: It must be submitted as both:
   o A soft copy: Must be submitted on a CD/ROM or a flash memory stick to the Dean
   Office and it must contain:
   ‚ñ™ MS Word or PDF of the project documentation contents
   ‚ñ™ Source code files (in a ZIP folder) [Project 2 only]
   ‚ñ™ Project presentation slides (PPT or PDF)
   ‚ñ™ Any supplementary materials (e.g., datasets, user manuals)
   o A Printed Hard Copy: Must be submitted to the Dean office as Hard Leather-bound
   documentation (5 ‚Äì Copies).
-  The cover should have:
   ‚ñ™ A logo for both NMU and CSE in addition to an optional logo for the project
   ‚ñ™ An academic title of the project with an optional commercial title.
   ‚ñ™ The name of the main supervisor and the assistants
   ‚ñ™ The names of the team members
   ‚ñ™ The Academic Graduation Year
   Poster (Pose) Preparation Instructions (Optional-Project 2 only)
   a. Size and Orientation
   ‚Ä¢
   Standard Size: A1 (594 mm √ó 841 mm) or A0 (841 mm √ó 1189 mm)
   ‚Ä¢
   Orientation: Preferably portrait unless otherwise specified
   üß± b. Recommended Poster Structure
   Section
   Description
   Title
   Large, bold project title at the top
   Student Info
   Names, ID numbers, department, supervisor
   Introduction
   Problem background, motivation
   Objectives
   Clear goals of the project
   Methodology
   Brief system design, tools, architecture diagram
   Implementation
   Screenshots, circuit images, block diagram
   Results
   Graphs, sample outputs, testing outcomes
   Conclusion & Future Work Summary and possible improvements
   QR Code (Optional)
   Link to full documentation or demo video
   üé® c. Design Tips
   ‚Ä¢
   Use simple, professional colors (white background is best)
   ‚Ä¢
   Use bullet points, not paragraphs
   ‚Ä¢
   Use large fonts (24 pt for text, 36‚Äì48 pt for titles)
   ‚Ä¢
   Include visuals: diagrams, flowcharts, screenshots, photos
   ‚Ä¢
   Avoid clutter‚Äîleave white space for easy reading
   üè≥Ô∏è 2. Banner Preparation Instructions (Optional ‚Äì Project 2 only)
   üìê a. Size
   ‚Ä¢
   Typical banner size:
   Width: 1.5 to 2 meters
   Height: 0.5 to 0.75 meters
   (Check showroom display stand size before printing)
   üìã b. Content to Include
   ‚Ä¢
   Project title (centered, large font)
   ‚Ä¢
   Student(s) name(s) and ID(s)
   ‚Ä¢
   Supervisor‚Äôs name
   ‚Ä¢
   University, department logo (left)
   ‚Ä¢
   Year or session (right)
   ‚Ä¢
   Optional slogan or one-line project summary
   üé® c. Banner Design Tips
   ‚Ä¢
   Use contrasting colors for visibility
   ‚Ä¢
   Ensure all text is readable from a distance
   ‚Ä¢
   Keep it minimal and bold
   ‚Ä¢
   Use vector graphics or high-resolution images only
   üìç 3. Printing and Setup
   ‚Ä¢
   Use high-resolution PDF format for printing
   ‚Ä¢
   Test print a small version to check layout and clarity
   ‚Ä¢
   Mount the poster on a foam board or easel if required
   ‚Ä¢
   Hang or place the banner above or near your display table
   üì∑ 4. Bonus Tips for Display Day
   ‚Ä¢
   Wear professional or project-branded attire
   ‚Ä¢
   Place a laptop/device for demo next to your poster
   ‚Ä¢
   Bring extra handouts or business cards (optional)
   ‚Ä¢
   Be ready with a 1-minute verbal pitch for visitors

---

-  [x] Slide 1: Title SlideProject Name (e.g., "VisionAgent: Context-Aware Wearable Intelligence").Your name, supervisor, and institution.
-  [x] Slide 2: The Problem StatementFocus on "Cognitive Overload" or "Information Friction." Why is pulling out a phone inefficient for real-time tasks?
-  [x] Slide 3: The Solution (The "Agentic" Angle)Define what makes your glasses different from standard AR. Emphasis on proactive vs. reactive assistance (the glasses understand what you are doing before you ask).Part 2: Technical Architecture
-  [x] Slide 4: System Overview (High-Level)A block diagram showing the flow: Sensors (Input) ‚Üí Perception (AI) ‚Üí Action (Output).
-  [x] Slide 5: Hardware SpecificationsComponents: Camera, Microphone, Bone Conduction Audio, Micro-controller (ESP32-S3, Raspberry Pi CM4, etc.), and Battery.
-  [x] Slide 6: The Software Stack & AI PipelineVision: (e.g., YOLO, CLIP, or GPT-4o-vision) for object recognition.LLM/Agent: The "Brain" (e.g., LangChain or AutoGPT) that manages memory and task planning.Context Engine: How the glasses store "short-term memory" of what they've seen.
-  [x] Slide 7: Multimodal InteractionHow the user interacts: Voice, gesture, or gaze.Part 3: Business & Strategy (As Requested)
-  [ ] Slide 8: Business Model Canvas (BMC)You should present this as a clear table. Key sections to highlight:Value Proposition: "Eyes-free, hands-free context-aware intelligence."Customer Segments: Industrial workers, the visually impaired, or tech early-adopters.Revenue Streams: Hardware sales + "AI-as-a-Service" subscription.
-  [ ] Slide 9: Market Analysis & CompetitorsA comparison table: Meta Ray-Bans (No display/limited agent) vs. Apple Vision Pro (Too bulky) vs. Your Project (The middle ground).
-  [x] Slide 10: Target Use CasesScenario A: Assisted repair (identifying tools/parts).Scenario B: Social/Accessibility (reading menus, recognizing faces for the blind).Part 4: Implementation & Results
-  [ ] Slide 11: The Prototype (Physical)Photos of your actual build. Highlight the 3D printing or assembly process.
-  [ ] Slide 12: Testing & Performance DataLatency (How fast does the agent respond?), Accuracy of object recognition, and Battery life.
-  [ ] Slide 13: Ethical Considerations & PrivacyCrucial for this topic: How do you handle the "always-on" camera? Data encryption and the "Privacy LED" indicator.Part 5: Conclusion
-  [ ] Slide 14: Future RoadmapMiniaturization, integration with Prescription lenses, and local "On-Device" processing to reduce cloud reliance.
-  [ ] Slide 15: Conclusion & Key TakeawaysSummarize the impact of agentic wearables.
-  [ ] Slide 16: Q&A / ReferencesSuggested Business Model Canvas (Quick Reference)Key PartnersKey ActivitiesValue PropositionsCustomer RelationshipsCustomer SegmentsAI Providers (OpenAI/Google), Lens ManufacturersSoftware Dev, Hardware DesignHands-free real-time problem solvingSubscription-based updatesField Engineers, Visually Impaired, StudentsKey ResourcesChannelsCost StructureRevenue StreamsProprietary AI Agents, SensorsDirect-to-Consumer, Enterprise TechR&D, Manufacturing, Cloud Server costsUnit Sales, Pro-AI SubscriptionTechnical Must-Haves for your Presentation:A Video Demo: Since "Agentic" behavior is hard to explain, show a 60-second clip of the glasses identifying an object and giving advice without being prompted.The "Failure"
-  [ ] Slide: Judges love to see what went wrong and how you fixed it. It shows engineering maturity.

---

-  [ ] better uni logo
-  [ ] remove graduation project from title
-  [ ] put the faculty name after logo
-  [ ] put team logo
-  [x] add Supervised by: Associate Professor. Aya Zoghby
-  [ ] add New Mansoura, 2025
-  [ ] add slogan "SmartVision", "AlexOracle", "OmniVision", "Cerebro"
-  [x] fix my name in the file
-  [x] ABSTRACT

        Modern wearable technologies aim to enhance human‚Äìtechnology interaction; however, existing smart glasses solutions remain limited in personalization, contextual awareness, and seamless multimodal integration. This paper presents an advanced AI-powered smart glasses system designed to improve daily communication, productivity, accessibility, and decision-making through intelligent, hands-free interaction.
        The proposed system integrates speech recognition, real-time multilingual translation, large language models, computer vision, augmented reality, navigation, and smart home connectivity into a unified wearable platform. A YOLO-based computer vision module enables real-time object detection and face recognition, allowing personalized and context-aware interactions. Indoor navigation is supported through a custom mapping and graph-based routing approach, providing accurate guidance in complex indoor environments.
        Speech input is transcribed using a multilingual automatic speech recognition model and processed by a large language model to understand user intent and generate appropriate responses, which are delivered through natural text-to-speech output. A companion mobile and web platform enables device management, smart home control, accessibility customization, and real-time system monitoring.
        The system is designed with inclusivity as a core principle, supporting users with disabilities through voice-based interaction, visual aids, and hands-free operation, while also enhancing safety and efficiency in daily tasks. Experimental analysis and competitor comparison demonstrate that the proposed solution addresses key limitations of existing smart glasses platforms, particularly in advanced computer vision, indoor navigation, and AI-driven personalization.

-  [x] fix bookmarks
-  [ ] TABLE OF CONTENTS
-  [ ] ABSTRACT
-  [ ] 1
-  [ ] ACKNOWLEDGEMENTS
-  [ ] 2
-  [ ] TABLE OF CONTENTS
-  [ ] 3
-  [ ] LIST OF TABLES
-  [ ] 4
-  [ ] LIST OF FIGURES
-  [ ] 5
-  [ ] SYMBOLS & ABBREVIATIONS
-  [ ] 6
-  [ ] 1.
-  [ ] INTRODUCTION
-  [ ] 1
-  [ ] 1.1.
-  [ ] Problem Statement
-  [ ] 1
-  [ ] 1.2.
-  [ ] Project Purpose
-  [ ] 2
-  [ ] 1.3.
-  [ ] Project Scope
-  [ ] 3
-  [ ] 1.4.
-  [ ] Objectives and Success Criteria of the Project
-  [ ] 4
-  [ ] 1.5.
-  [ ] Report Outline
-  [ ] 4
-  [ ] 2.
-  [ ] RELATED WORK
-  [ ] 5
-  [ ] 2.1.
-  [ ] Existing Systems
-  [ ] 5
-  [ ] 2.2.
-  [ ] Overall Problems of Existing Systems
-  [ ] 8
-  [ ] 2.3.
-  [ ] Comparison Between Existing and Proposed Method
-  [ ] 10
-  [ ] 3.
-  [ ] METHODOLOGY
-  [ ] 12
-  [ ] 3.1.
-  [ ] Design Overview
-  [ ] 13
-  [ ] 3.2.
-  [ ] System Architecture
-  [ ] 21
-  [ ] 3.2.1.
-  [ ] Module A
-  [ ] 22
-  [ ] 3.2.2.
-  [ ] Module B
-  [ ] 23
-  [ ] 3.2.3.
-  [ ] Module C
-  [ ] 24
-  [ ] 3.2.4.
-  [ ] Module D
-  [ ] 25
-  [ ] 3.2.5.
-  [ ] Module E
-  [ ] 26
-  [ ] 3.3.
-  [ ] System Software
-  [ ] 27
-  [ ] 4.
-  [ ] EXPERIMENTAL RESULTS
-  [ ] 29
-  [ ] 5.
-  [ ] DISCUSSION
-  [ ] 32
-  [ ] 6.
-  [ ] BUSINESS PLAN
-  [ ] 34
-  [ ] 7.
-  [ ] CONCLUSIONS
-  [ ] 39
-  [ ] REFERENCES
-  [ ] list of tables is wrong
-  [ ] change introduction fully
-  [ ] fix project purpose
-  [ ] label tables and figures appropriately

---

Problem Statement: Cognitive Overload and Information Friction

In modern digital environments, users increasingly rely on smartphones to access information, communicate, and perform real-time tasks. However, the smartphone-centric interaction model introduces significant cognitive overload and information friction, particularly in time-sensitive or attention-critical situations. Cognitive overload occurs when users are required to divide their attention between their physical environment and a digital interface, while information friction refers to the unnecessary effort and delays involved in accessing, navigating, and interpreting information.

Pulling out a smartphone to perform simple tasks‚Äîsuch as checking directions, replying to a message, translating speech, or retrieving contextual information‚Äîrequires multiple sequential actions: locating the device, unlocking it, navigating through applications, and interpreting visual content. Each step interrupts the user‚Äôs current cognitive flow and demands focused visual and motor attention. This process increases mental workload, slows task completion, and raises the likelihood of errors.

In real-time contexts such as navigation, social interaction, learning, or driving, these interruptions are particularly inefficient and potentially unsafe. Users must repeatedly shift attention away from their surroundings, resulting in reduced situational awareness and increased cognitive strain. For individuals with disabilities, high workloads, or complex multitasking demands, this interaction model further exacerbates accessibility challenges.

Despite advances in mobile technology, smartphones remain fundamentally screen-centric and reactive, offering limited contextual awareness and proactive assistance. This creates a gap between the user‚Äôs intent and the system‚Äôs response, forcing users to actively ‚Äúpull‚Äù information rather than receiving it seamlessly when needed.

Therefore, there is a critical need for an interaction paradigm that minimizes cognitive load and reduces information friction by enabling hands-free, context-aware, and continuous access to information. Addressing this problem requires moving beyond traditional smartphone interfaces toward wearable systems that integrate seamlessly with human perception and real-world activity.

---

This project presents an AI-powered Smart Glasses system designed to enhance daily communication, productivity, accessibility, and indoor navigation. The solution integrates computer vision, speech recognition, large language models, augmented reality, and IoT into a single, low-cost wearable device. Using real-time object detection, multilingual voice interaction (Arabic and English), and AR-based indoor navigation, the system provides hands-free, context-aware assistance in complex indoor environments such as universities, hospitals, and enterprise buildings. By leveraging open-source AI models and affordable hardware, the project delivers an intelligent, scalable, and accessible smart companion that improves user independence, safety, and efficiency while supporting smart building, telecommunication infrastructures and empowering the customer by keeping their data and privacy safe giving them the option of monetizing their own data later down the line. all of that in a one time cost product with no subscriptions unless connected to our cloud for extra services.

---

-  Prompts:
   1. always use the venv (Smart_Glasses)
   2. index and read the whole project before changing anything, understand the project and make documentation for it
   3. search_web tool works but visiondetect is seemingly broken
   4. "hey nova" works but it queues and waits for me to do manual record before processing the automatic one when they should be separate
   5. "hey nova" should have the same logic as the manual record
   6. clean up repository of useless files
   7. provide ideas on integrating augmented reality to the project in the form of future work
   8. fix text to speech
   9. streamlit crashes sometimes
   10. refactor the code if necessary.

Traceback:
pygame-ce 2.5.2 (SDL 2.30.8, Python 3.12.1)
Calibrating microphone...
Microphone calibrated
Wake word detection active. Say 'Nova' or 'Hey Nova' to activate.
Wake word system started
Wake-word system auto-started successfully
Wake-word system is running. State: SystemState.IDLE
Wake word detected: 'nova' (confidence: 1.00)
[MIC] Listening for command...
[CMD] Command received: 'what day is'
WAKEWORD CALLBACK: on_command_received('what day is')



project name
idea companion, nav, modularity, privacy
Target audience
architecture
userflow
comparison table
metrics
Business model canvas

Docs:- 
   -  Acknowledgements ‚úÖ
   -  fix table of contents
   -  fixed style ‚úÖ
   -  fixed duplication ‚úÖ
   -  fix tables